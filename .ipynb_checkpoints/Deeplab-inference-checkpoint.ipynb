{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with a single image\n",
    "\n",
    "We load the necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision import models\n",
    "from fastai.vision.all import *\n",
    "from fastai.metrics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback import *\n",
    "\n",
    "# SemTorch\n",
    "from semtorch import get_segmentation_learner\n",
    "\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# HRNet\n",
    "\n",
    "model = torch.jit.load(\"deeplab.pth\")\n",
    "model = model.cpu()\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load correctly the image for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "def transform_image(image):\n",
    "    my_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(\n",
    "                                            [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])])\n",
    "    image_aux = image\n",
    "    return my_transforms(image_aux).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply inference to a complete folder as follows. The predictions are later employed for training a new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('dataset/semi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in path.ls():\n",
    "    image = Image.open(file)\n",
    "    image = transforms.Resize((480,640))(image)\n",
    "    tensor = transform_image(image=image)\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tensor)\n",
    "    outputs = torch.argmax(outputs,1)\n",
    "    mask = np.array(outputs.cpu())\n",
    "    mask[mask==4]=255\n",
    "    mask[mask==1]=150\n",
    "    mask[mask==3]=76\n",
    "    mask[mask==2]=29\n",
    "    mask=np.reshape(mask,(480*640))\n",
    "    new  = np.zeros((480*640,3),dtype='uint8')\n",
    "\n",
    "    for i,v in enumerate(mask):\n",
    "        if(v==150):\n",
    "            new[i]=[0,255,0]\n",
    "        if(v==76):\n",
    "            new[i]=[255,0,0]\n",
    "        if(v==29):\n",
    "            new[i]=[0,0,255]\n",
    "        if(v==0 or v==255):\n",
    "            new[i]=[v,v,v]\n",
    "\n",
    "    maskRGBShow = Image.fromarray(np.reshape(new,(480,640,3)))\n",
    "    maskRGBShow.save('dataset/dataset/Labels/trainSemi/gt'+file.name.replace('color','').replace('.jpg','.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply inference to a single image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('dataset/semi/color00247.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = transforms.Resize((480,640))(image)\n",
    "tensor = transform_image(image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(tensor)\n",
    "\n",
    "outputs = torch.argmax(outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(outputs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask==4]=255\n",
    "mask[mask==1]=150\n",
    "mask[mask==3]=76\n",
    "mask[mask==2]=29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.reshape(mask,(480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskShow = Image.fromarray(mask.astype('uint8'))\n",
    "maskShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.reshape(np.array(maskShow),(480*640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new  = np.zeros((480*640,3),dtype='uint8')\n",
    "\n",
    "for i,v in enumerate(temp):\n",
    "    if(v==150):\n",
    "        new[i]=[0,255,0]\n",
    "    if(v==76):\n",
    "        new[i]=[255,0,0]\n",
    "    if(v==29):\n",
    "        new[i]=[0,0,255]\n",
    "    if(v==0 or v==255):\n",
    "        new[i]=[v,v,v]\n",
    "    \n",
    "\n",
    "maskRGBShow = Image.fromarray(np.reshape(new,(480,640,3)))\n",
    "maskRGBShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskRGBShow.save('deeplab_pred_155.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
